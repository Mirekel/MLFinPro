{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-08T05:28:33.399103Z",
     "iopub.status.busy": "2025-06-08T05:28:33.398037Z",
     "iopub.status.idle": "2025-06-08T05:28:33.538344Z",
     "shell.execute_reply": "2025-06-08T05:28:33.537412Z",
     "shell.execute_reply.started": "2025-06-08T05:28:33.399064Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Movies dataset shape: (62423, 3)\n",
      "Ratings dataset shape: (100000, 4)\n",
      "\n",
      "Movies dataset preview:\n",
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "\n",
      "Ratings dataset preview:\n",
      "   userId  movieId  rating   timestamp\n",
      "0       1      296     5.0  1147880044\n",
      "1       1      306     3.5  1147868817\n",
      "2       1      307     5.0  1147868828\n",
      "3       1      665     5.0  1147878820\n",
      "4       1      899     3.5  1147868510\n"
     ]
    }
   ],
   "source": [
    "# Hybrid Movie Recommender System\n",
    "# Combining User-based CF, Item-based CF, and Content-based Filtering\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.spatial.distance import cosine\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the datasets\n",
    "print(\"Loading datasets...\")\n",
    "movies = pd.read_csv('./datasets/movies.csv')\n",
    "ratings = pd.read_csv('./datasets/ratings.csv', nrows=100000)\n",
    "\n",
    "print(f\"Movies dataset shape: {movies.shape}\")\n",
    "print(f\"Ratings dataset shape: {ratings.shape}\")\n",
    "print(\"\\nMovies dataset preview:\")\n",
    "print(movies.head())\n",
    "print(\"\\nRatings dataset preview:\")\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T05:28:33.540124Z",
     "iopub.status.busy": "2025-06-08T05:28:33.539806Z",
     "iopub.status.idle": "2025-06-08T05:28:33.550041Z",
     "shell.execute_reply": "2025-06-08T05:28:33.549132Z",
     "shell.execute_reply.started": "2025-06-08T05:28:33.540096Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique users: 757\n",
      "Unique movies: 9786\n",
      "Total ratings: 100000\n",
      "Rating range: 0.5 - 5.0\n",
      "Average rating: 3.59\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique users: {ratings['userId'].nunique()}\")\n",
    "print(f\"Unique movies: {ratings['movieId'].nunique()}\")\n",
    "print(f\"Total ratings: {len(ratings)}\")\n",
    "print(f\"Rating range: {ratings['rating'].min()} - {ratings['rating'].max()}\")\n",
    "print(f\"Average rating: {ratings['rating'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T05:28:33.551902Z",
     "iopub.status.busy": "2025-06-08T05:28:33.551016Z",
     "iopub.status.idle": "2025-06-08T05:28:33.595442Z",
     "shell.execute_reply": "2025-06-08T05:28:33.594671Z",
     "shell.execute_reply.started": "2025-06-08T05:28:33.551873Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged dataset shape: (100000, 6)\n",
      "\n",
      "After filtering:\n",
      "Active users: 757\n",
      "Popular movies: 2176\n",
      "Remaining ratings: 81298\n"
     ]
    }
   ],
   "source": [
    "data = ratings.merge(movies, on='movieId', how='left')\n",
    "print(f\"\\nMerged dataset shape: {data.shape}\")\n",
    "\n",
    "min_user_ratings = 20\n",
    "min_movie_ratings = 10\n",
    "\n",
    "user_counts = ratings['userId'].value_counts()\n",
    "movie_counts = ratings['movieId'].value_counts()\n",
    "\n",
    "active_users = user_counts[user_counts >= min_user_ratings].index\n",
    "popular_movies = movie_counts[movie_counts >= min_movie_ratings].index\n",
    "\n",
    "filtered_ratings = ratings[\n",
    "    (ratings['userId'].isin(active_users)) & \n",
    "    (ratings['movieId'].isin(popular_movies))\n",
    "]\n",
    "\n",
    "print(f\"\\nAfter filtering:\")\n",
    "print(f\"Active users: {filtered_ratings['userId'].nunique()}\")\n",
    "print(f\"Popular movies: {filtered_ratings['movieId'].nunique()}\")\n",
    "print(f\"Remaining ratings: {len(filtered_ratings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T05:28:33.597346Z",
     "iopub.status.busy": "2025-06-08T05:28:33.596973Z",
     "iopub.status.idle": "2025-06-08T05:28:33.644131Z",
     "shell.execute_reply": "2025-06-08T05:28:33.643382Z",
     "shell.execute_reply.started": "2025-06-08T05:28:33.597297Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set: 65038 ratings\n",
      "Test set: 16260 ratings\n"
     ]
    }
   ],
   "source": [
    "# Create train-test split\n",
    "train_data, test_data = train_test_split(filtered_ratings, test_size=0.2, random_state=42, stratify=filtered_ratings['userId'])\n",
    "\n",
    "print(f\"\\nTrain set: {len(train_data)} ratings\")\n",
    "print(f\"Test set: {len(test_data)} ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T05:28:33.645469Z",
     "iopub.status.busy": "2025-06-08T05:28:33.645093Z",
     "iopub.status.idle": "2025-06-08T05:28:33.756387Z",
     "shell.execute_reply": "2025-06-08T05:28:33.755494Z",
     "shell.execute_reply.started": "2025-06-08T05:28:33.645447Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train matrix shape: (757, 2176)\n",
      "Matrix sparsity: 96.05%\n"
     ]
    }
   ],
   "source": [
    "def create_user_item_matrix(data):\n",
    "    return data.pivot_table(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "\n",
    "train_matrix = create_user_item_matrix(train_data)\n",
    "test_matrix = create_user_item_matrix(test_data)\n",
    "\n",
    "print(f\"\\nTrain matrix shape: {train_matrix.shape}\")\n",
    "print(f\"Matrix sparsity: {(train_matrix == 0).sum().sum() / (train_matrix.shape[0] * train_matrix.shape[1]) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T05:30:03.976174Z",
     "iopub.status.busy": "2025-06-08T05:30:03.974981Z",
     "iopub.status.idle": "2025-06-08T05:30:04.014359Z",
     "shell.execute_reply": "2025-06-08T05:30:04.013460Z",
     "shell.execute_reply.started": "2025-06-08T05:30:03.976115Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class UserBasedCF:\n",
    "    def __init__(self, k=50):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, train_matrix):\n",
    "        self.train_matrix = train_matrix\n",
    "        self.user_ids = train_matrix.index.tolist()\n",
    "        self.user_idx_map = {u: i for i, u in enumerate(self.user_ids)}\n",
    "        self.user_similarity = cosine_similarity(train_matrix.values)\n",
    "        np.fill_diagonal(self.user_similarity, 0)\n",
    "\n",
    "    def predict(self, user_id, movie_id):\n",
    "        if user_id not in self.train_matrix.index or movie_id not in self.train_matrix.columns:\n",
    "            return np.nanmean(self.train_matrix.values)\n",
    "\n",
    "        u_idx = self.user_idx_map[user_id]\n",
    "        sims = self.user_similarity[u_idx]\n",
    "        movie_col = self.train_matrix[movie_id]\n",
    "        rated = movie_col[movie_col > 0]\n",
    "\n",
    "        if rated.empty:\n",
    "            return np.nanmean(self.train_matrix.values)\n",
    "\n",
    "        indices = [self.user_idx_map[uid] for uid in rated.index]\n",
    "        ratings = rated.values\n",
    "        sim_scores = sims[indices]\n",
    "\n",
    "        top_k = np.argsort(sim_scores)[-self.k:]\n",
    "        top_ratings = ratings[top_k]\n",
    "        top_sims = sim_scores[top_k]\n",
    "\n",
    "        denom = np.sum(np.abs(top_sims))\n",
    "        return np.dot(top_ratings, top_sims) / denom if denom else np.nanmean(self.train_matrix.values)\n",
    "    \n",
    "    def recommend_movies(self, user_id, n=10):\n",
    "        if user_id not in self.train_matrix.index:\n",
    "            return []\n",
    "\n",
    "        user_ratings = self.train_matrix.loc[user_id]\n",
    "        unrated = user_ratings[user_ratings == 0].index\n",
    "\n",
    "        predictions = [(m, self.predict(user_id, m)) for m in unrated]\n",
    "        return sorted(predictions, key=lambda x: x[1], reverse=True)[:n]\n",
    "\n",
    "class ItemBasedCF:\n",
    "    def __init__(self, k=50):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, train_matrix):\n",
    "        self.train_matrix = train_matrix\n",
    "        self.movie_ids = train_matrix.columns.tolist()\n",
    "        self.movie_idx_map = {m: i for i, m in enumerate(self.movie_ids)}\n",
    "        self.item_similarity = cosine_similarity(train_matrix.T.values)\n",
    "        np.fill_diagonal(self.item_similarity, 0)\n",
    "\n",
    "    def predict(self, user_id, movie_id):\n",
    "        if user_id not in self.train_matrix.index or movie_id not in self.train_matrix.columns:\n",
    "            return np.nanmean(self.train_matrix.values)\n",
    "\n",
    "        m_idx = self.movie_idx_map[movie_id]\n",
    "        sims = self.item_similarity[m_idx]\n",
    "        user_row = self.train_matrix.loc[user_id]\n",
    "        rated = user_row[user_row > 0]\n",
    "\n",
    "        if rated.empty:\n",
    "            return np.nanmean(self.train_matrix.values)\n",
    "\n",
    "        indices = [self.movie_idx_map[mid] for mid in rated.index]\n",
    "        ratings = rated.values\n",
    "        sim_scores = sims[indices]\n",
    "\n",
    "        top_k = np.argsort(sim_scores)[-self.k:]\n",
    "        top_ratings = ratings[top_k]\n",
    "        top_sims = sim_scores[top_k]\n",
    "\n",
    "        denom = np.sum(np.abs(top_sims))\n",
    "        return np.dot(top_ratings, top_sims) / denom if denom else np.nanmean(self.train_matrix.values)\n",
    "    \n",
    "    def recommend_movies(self, user_id, n=10):\n",
    "        if user_id not in self.train_matrix.index:\n",
    "            return []\n",
    "\n",
    "        user_ratings = self.train_matrix.loc[user_id]\n",
    "        unrated = user_ratings[user_ratings == 0].index\n",
    "\n",
    "        predictions = [(m, self.predict(user_id, m)) for m in unrated]\n",
    "        return sorted(predictions, key=lambda x: x[1], reverse=True)[:n]\n",
    "\n",
    "class ContentBasedCF:\n",
    "    def __init__(self):\n",
    "        self.tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "    def fit(self, train_matrix, movies_df):\n",
    "        self.train_matrix = train_matrix\n",
    "        self.movie_ids = train_matrix.columns.tolist()\n",
    "        movies = movies_df[movies_df['movieId'].isin(self.movie_ids)].copy()\n",
    "        movies['genres'] = movies['genres'].fillna('Unknown')\n",
    "        self.movie_features = self.tfidf.fit_transform(movies['genres'])\n",
    "        self.movie_similarity = cosine_similarity(self.movie_features)\n",
    "        self.movie_idx_map = {mid: i for i, mid in enumerate(movies['movieId'])}\n",
    "\n",
    "    def predict(self, user_id, movie_id):\n",
    "        if user_id not in self.train_matrix.index or movie_id not in self.movie_idx_map:\n",
    "            return np.nanmean(self.train_matrix.values)\n",
    "\n",
    "        user_ratings = self.train_matrix.loc[user_id]\n",
    "        rated = user_ratings[user_ratings > 0]\n",
    "\n",
    "        if rated.empty:\n",
    "            return np.nanmean(self.train_matrix.values)\n",
    "\n",
    "        m_idx = self.movie_idx_map[movie_id]\n",
    "        total, weight = 0, 0\n",
    "\n",
    "        for rid, rating in rated.items():\n",
    "            if rid in self.movie_idx_map:\n",
    "                r_idx = self.movie_idx_map[rid]\n",
    "                sim = self.movie_similarity[m_idx, r_idx]\n",
    "                total += sim * rating\n",
    "                weight += sim\n",
    "\n",
    "        return total / weight if weight else np.nanmean(self.train_matrix.values)\n",
    "    \n",
    "    def recommend_movies(self, user_id, n=10):\n",
    "        if user_id not in self.train_matrix.index:\n",
    "            return []\n",
    "\n",
    "        user_ratings = self.train_matrix.loc[user_id]\n",
    "        unrated = user_ratings[user_ratings == 0].index\n",
    "\n",
    "        predictions = [(m, self.predict(user_id, m)) for m in unrated]\n",
    "        return sorted(predictions, key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "class HybridRecommender:\n",
    "    def __init__(self, user_weight=0.3, item_weight=0.4, content_weight=0.3):\n",
    "        self.user_weight = user_weight\n",
    "        self.item_weight = item_weight\n",
    "        self.content_weight = content_weight\n",
    "        \n",
    "        self.user_cf = UserBasedCF()\n",
    "        self.item_cf = ItemBasedCF()\n",
    "        self.content_cf = ContentBasedCF()\n",
    "\n",
    "    def fit(self, train_matrix, movies_df):\n",
    "        self.user_cf.fit(train_matrix)\n",
    "        self.item_cf.fit(train_matrix)\n",
    "        self.content_cf.fit(train_matrix, movies_df)\n",
    "\n",
    "    def predict(self, user_id, movie_id):\n",
    "        preds = np.array([\n",
    "            self.user_cf.predict(user_id, movie_id),\n",
    "            self.item_cf.predict(user_id, movie_id),\n",
    "            self.content_cf.predict(user_id, movie_id)\n",
    "        ])\n",
    "        weights = np.array([self.user_weight, self.item_weight, self.content_weight])\n",
    "        return np.dot(preds, weights)\n",
    "\n",
    "    def recommend_movies(self, user_id, n=10):\n",
    "        if user_id not in self.user_cf.train_matrix.index:\n",
    "            return []\n",
    "\n",
    "        user_ratings = self.user_cf.train_matrix.loc[user_id]\n",
    "        unrated = user_ratings[user_ratings == 0].index\n",
    "\n",
    "        predictions = [(m, self.predict(user_id, m)) for m in unrated]\n",
    "        return sorted(predictions, key=lambda x: x[1], reverse=True)[:n]\n",
    "\n",
    "class RecommenderEvaluator:\n",
    "    def __init__(self, threshold=3.5):\n",
    "        self.threshold = threshold  # Rating threshold for relevance\n",
    "        \n",
    "    def precision_at_k(self, actual, predicted, k=10):\n",
    "        \"\"\"Calculate Precision@K\"\"\"\n",
    "        if k > len(predicted):\n",
    "            k = len(predicted)\n",
    "        \n",
    "        predicted_k = predicted[:k]\n",
    "        relevant_predicted = sum(1 for item in predicted_k if item in actual)\n",
    "        \n",
    "        return relevant_predicted / k if k > 0 else 0\n",
    "    \n",
    "    def recall_at_k(self, actual, predicted, k=10):\n",
    "        \"\"\"Calculate Recall@K\"\"\"\n",
    "        if k > len(predicted):\n",
    "            k = len(predicted)\n",
    "        \n",
    "        predicted_k = predicted[:k]\n",
    "        relevant_predicted = sum(1 for item in predicted_k if item in actual)\n",
    "        \n",
    "        return relevant_predicted / len(actual) if len(actual) > 0 else 0\n",
    "    \n",
    "    def ndcg_at_k(self, actual, predicted, k=10):\n",
    "        \"\"\"Calculate NDCG@K\"\"\"\n",
    "        if k > len(predicted):\n",
    "            k = len(predicted)\n",
    "        \n",
    "        predicted_k = predicted[:k]\n",
    "\n",
    "        dcg = 0\n",
    "        for i, item in enumerate(predicted_k):\n",
    "            if item in actual:\n",
    "                dcg += 1 / np.log2(i + 2)\n",
    "\n",
    "        idcg = sum(1 / np.log2(i + 2) for i in range(min(len(actual), k)))\n",
    "        \n",
    "        return dcg / idcg if idcg > 0 else 0\n",
    "    \n",
    "    def mean_average_precision(self, actual_dict, predicted_dict, k=10):\n",
    "        \"\"\"Calculate Mean Average Precision\"\"\"\n",
    "        ap_scores = []\n",
    "        \n",
    "        for user_id in actual_dict:\n",
    "            if user_id in predicted_dict:\n",
    "                actual = actual_dict[user_id]\n",
    "                predicted = predicted_dict[user_id][:k]\n",
    "                \n",
    "                if len(actual) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate Average Precision\n",
    "                precision_scores = []\n",
    "                relevant_count = 0\n",
    "                \n",
    "                for i, item in enumerate(predicted):\n",
    "                    if item in actual:\n",
    "                        relevant_count += 1\n",
    "                        precision_scores.append(relevant_count / (i + 1))\n",
    "                \n",
    "                ap = sum(precision_scores) / len(actual) if len(actual) > 0 else 0\n",
    "                ap_scores.append(ap)\n",
    "        \n",
    "        return np.mean(ap_scores) if ap_scores else 0\n",
    "    \n",
    "    def evaluate_model(self, model, test_data, train_matrix, k=10):\n",
    "        test_users = test_data['userId'].unique()\n",
    "        \n",
    "        actual_relevant = {}\n",
    "        predicted_items = {}\n",
    "        \n",
    "        print(f\"Evaluating model for {len(test_users)} users...\")\n",
    "        \n",
    "        for i, user_id in enumerate(test_users[:100]):  # Limit to 100 users for faster evaluation\n",
    "            if i % 20 == 0:\n",
    "                print(f\"Progress: {i}/{min(100, len(test_users))}\")\n",
    "\n",
    "            user_test_data = test_data[test_data['userId'] == user_id]\n",
    "            actual_relevant[user_id] = set(user_test_data[user_test_data['rating'] >= self.threshold]['movieId'])\n",
    "\n",
    "            recommendations = model.recommend_movies(user_id, n=k)\n",
    "            predicted_items[user_id] = [movie_id for movie_id, _ in recommendations]\n",
    "        \n",
    "        precision_scores = []\n",
    "        recall_scores = []\n",
    "        ndcg_scores = []\n",
    "        \n",
    "        for user_id in actual_relevant:\n",
    "            if user_id in predicted_items:\n",
    "                actual = list(actual_relevant[user_id])\n",
    "                predicted = predicted_items[user_id]\n",
    "                \n",
    "                precision_scores.append(self.precision_at_k(actual, predicted, k))\n",
    "                recall_scores.append(self.recall_at_k(actual, predicted, k))\n",
    "                ndcg_scores.append(self.ndcg_at_k(actual, predicted, k))\n",
    "        \n",
    "        map_score = self.mean_average_precision(actual_relevant, predicted_items, k)\n",
    "        \n",
    "        results = {\n",
    "            'Precision@K': np.mean(precision_scores),\n",
    "            'Recall@K': np.mean(recall_scores),\n",
    "            'NDCG@K': np.mean(ndcg_scores),\n",
    "            'MAP': map_score\n",
    "        }\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T05:30:05.557174Z",
     "iopub.status.busy": "2025-06-08T05:30:05.556827Z",
     "iopub.status.idle": "2025-06-08T05:33:02.431333Z",
     "shell.execute_reply": "2025-06-08T05:33:02.430443Z",
     "shell.execute_reply.started": "2025-06-08T05:30:05.557121Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model for 757 users...\n",
      "Progress: 0/100\n",
      "Progress: 20/100\n",
      "Progress: 40/100\n",
      "Progress: 60/100\n",
      "Progress: 80/100\n",
      "----------------------------------------\n",
      "Precision@K: 0.0690\n",
      "Recall@K: 0.0257\n",
      "NDCG@K: 0.0733\n",
      "MAP: 0.0098\n"
     ]
    }
   ],
   "source": [
    "hybrid_model = HybridRecommender(user_weight=0.3, item_weight=0.4, content_weight=0.3)\n",
    "hybrid_model.fit(train_matrix, movies)\n",
    "\n",
    "evaluator = RecommenderEvaluator(threshold=3.5)\n",
    "results = evaluator.evaluate_model(hybrid_model, test_data, train_matrix, k=10)\n",
    "\n",
    "print(\"-\" * 40)\n",
    "for metric, score in results.items():\n",
    "    print(f\"{metric}: {score:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T05:37:04.987324Z",
     "iopub.status.busy": "2025-06-08T05:37:04.986543Z",
     "iopub.status.idle": "2025-06-08T05:37:06.478748Z",
     "shell.execute_reply": "2025-06-08T05:37:06.477851Z",
     "shell.execute_reply.started": "2025-06-08T05:37:04.987297Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 movie recommendations for User 1:\n",
      "------------------------------------------------------------\n",
      " 1. Usual Suspects, The (1995) (Predicted Rating: 4.30)\n",
      " 2. Godfather, The (1972) (Predicted Rating: 4.26)\n",
      " 3. Fight Club (1999) (Predicted Rating: 4.25)\n",
      " 4. Dirty Harry (1971) (Predicted Rating: 4.25)\n",
      " 5. Shawshank Redemption, The (1994) (Predicted Rating: 4.24)\n",
      " 6. Rosencrantz and Guildenstern Are Dead (1990) (Predicted Rating: 4.24)\n",
      " 7. Charade (1963) (Predicted Rating: 4.22)\n",
      " 8. Murder in the First (1995) (Predicted Rating: 4.21)\n",
      " 9. Red Rock West (1992) (Predicted Rating: 4.21)\n",
      "10. Dial M for Murder (1954) (Predicted Rating: 4.21)\n"
     ]
    }
   ],
   "source": [
    "sample_user = 1\n",
    "recommendations = hybrid_model.recommend_movies(sample_user, n=10)\n",
    "\n",
    "print(f\"\\nTop 10 movie recommendations for User {sample_user}:\")\n",
    "print(\"-\" * 60)\n",
    "for i, (movie_id, pred_rating) in enumerate(recommendations, 1):\n",
    "    movie_title = movies[movies['movieId'] == movie_id]['title'].iloc[0] if len(movies[movies['movieId'] == movie_id]) > 0 else \"Unknown\"\n",
    "    print(f\"{i:2d}. {movie_title} (Predicted Rating: {pred_rating:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "# import pickle\n",
    "# with open('model/recommender2.pkl','wb') as f:\n",
    "#     print(\"saving model...\")\n",
    "#     pickle.dump(hybrid_model, f)\n",
    "#     print('model saved...')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3375918,
     "sourceId": 5872805,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
